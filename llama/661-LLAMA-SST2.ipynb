{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41d40012-ab6d-4d04-99b7-a941989e6345",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c07cd71-b5ad-4140-b243-f3ba985418d7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 22 03:07:43 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.42.06              Driver Version: 555.42.06      CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  |   00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   37C    P0             44W /  300W |       1MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25d13bf0-174e-40ca-9f38-3b8bbf9ab38b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in /home/echung32/.local/lib/python3.11/site-packages (0.3.7)\n",
      "Requirement already satisfied: langchain-huggingface in /home/echung32/.local/lib/python3.11/site-packages (0.1.2)\n",
      "Requirement already satisfied: bitsandbytes in /home/echung32/.local/lib/python3.11/site-packages (0.44.1)\n",
      "Requirement already satisfied: datasets in /home/echung32/.local/lib/python3.11/site-packages (3.1.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /home/echung32/.local/lib/python3.11/site-packages (from langchain) (0.3.18)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /home/echung32/.local/lib/python3.11/site-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/echung32/.local/lib/python3.11/site-packages (from langchain) (0.1.143)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/echung32/.local/lib/python3.11/site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/echung32/.local/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/echung32/.local/lib/python3.11/site-packages (from langchain-huggingface) (0.26.1)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in /home/echung32/.local/lib/python3.11/site-packages (from langchain-huggingface) (3.3.0)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /home/echung32/.local/lib/python3.11/site-packages (from langchain-huggingface) (0.20.1)\n",
      "Requirement already satisfied: transformers>=4.39.0 in /home/echung32/.local/lib/python3.11/site-packages (from langchain-huggingface) (4.45.2)\n",
      "Requirement already satisfied: torch in /home/echung32/.local/lib/python3.11/site-packages (from bitsandbytes) (2.5.1)\n",
      "Requirement already satisfied: filelock in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/echung32/.local/lib/python3.11/site-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/echung32/.local/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/echung32/.local/lib/python3.11/site-packages (from datasets) (4.67.0)\n",
      "Requirement already satisfied: xxhash in /home/echung32/.local/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/echung32/.local/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: packaging in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/echung32/.local/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/echung32/.local/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/echung32/.local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
      "Requirement already satisfied: scipy in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.13.0)\n",
      "Requirement already satisfied: Pillow in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (10.2.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: networkx in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from torch->bitsandbytes) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from torch->bitsandbytes) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/echung32/.local/lib/python3.11/site-packages (from torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/echung32/.local/lib/python3.11/site-packages (from torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/echung32/.local/lib/python3.11/site-packages (from torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/echung32/.local/lib/python3.11/site-packages (from torch->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/echung32/.local/lib/python3.11/site-packages (from torch->bitsandbytes) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/echung32/.local/lib/python3.11/site-packages (from torch->bitsandbytes) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/echung32/.local/lib/python3.11/site-packages (from torch->bitsandbytes) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/echung32/.local/lib/python3.11/site-packages (from torch->bitsandbytes) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/echung32/.local/lib/python3.11/site-packages (from torch->bitsandbytes) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/echung32/.local/lib/python3.11/site-packages (from torch->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/echung32/.local/lib/python3.11/site-packages (from torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/echung32/.local/lib/python3.11/site-packages (from torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/echung32/.local/lib/python3.11/site-packages (from torch->bitsandbytes) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/echung32/.local/lib/python3.11/site-packages (from torch->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from transformers>=4.39.0->langchain-huggingface) (2023.10.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/echung32/.local/lib/python3.11/site-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: anyio in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/echung32/.local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/echung32/.local/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (2.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/apps/software/lang/Anaconda3/2024.02-1/lib/python3.11/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-huggingface bitsandbytes datasets matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29892287-eb2e-4212-b59a-73f4ad01d96f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from datasets import load_dataset\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e077a673-9bad-4e4d-8802-4f5a47adbe39",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Hugging Face API key:  ········\n"
     ]
    }
   ],
   "source": [
    "api_env_key = \"HUGGINGFACEHUB_API_TOKEN\"\n",
    "if os.environ.get(api_env_key) is None:\n",
    "    os.environ[api_env_key] = getpass.getpass(\n",
    "        \"Enter your Hugging Face API key: \"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6398bd9d-6dcd-43c3-9813-58b6eb09c3ad",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 03:07:59.554442: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-22 03:07:59.575670: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-22 03:07:59.582862: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-22 03:07:59.600858: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-22 03:08:01.761020: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5532a930d03481d8b42aa95e7cce965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    device=0, \n",
    "    pipeline_kwargs=dict(\n",
    "        max_new_tokens=512,\n",
    "        do_sample=True,\n",
    "        repetition_penalty=1.1,\n",
    "        pad_token_id = 128009 # extracted from chat_model.llm.pipeline.tokenizer.eos_token_id\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5882752d-4e7e-43fe-aba2-76cae1bf7e10",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "chat_model = ChatHuggingFace(llm=llm)\n",
    "chat_model.llm.pipeline.tokenizer.pad_token_id = chat_model.llm.pipeline.tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a437d96e-5ed6-4b37-a0f9-5ee712beddc0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128009\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(chat_model.llm.pipeline.tokenizer.eos_token_id)\n",
    "print(type(chat_model.llm.pipeline.tokenizer.eos_token_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fce28800-278c-419d-a765-959e97bb1a45",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'idx': [0, 1, 2, 3, 4], 'sentence': ['hide new secretions from the parental units ', 'contains no wit , only labored gags ', 'that loves its characters and communicates something rather beautiful about human nature ', 'remains utterly satisfied to remain the same throughout ', 'on the worst revenge-of-the-nerds clichés the filmmakers could dredge up '], 'label': [0, 0, 1, 0, 0]}\n",
      "{'idx': [0, 1, 2, 3, 4], 'sentence': [\"it 's a charming and often affecting journey . \", 'unflinchingly bleak and desperate ', 'allows us to hope that nolan is poised to embark a major career as a commercial yet inventive filmmaker . ', \"the acting , costumes , music , cinematography and sound are all astounding given the production 's austere locales . \", \"it 's slow -- very , very slow . \"], 'label': [1, 0, 1, 1, 0]}\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"sst2\")\n",
    "\n",
    "train_set = dataset[\"train\"]\n",
    "test_set = dataset[\"test\"]\n",
    "\n",
    "print(train_set[:5])\n",
    "print(test_set[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86dda839-ef4e-4ced-a26d-b6638751c72c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'idx': 13189, 'sentence': 'at every opportunity to do something clever ', 'label': 1}, {'idx': 3002, 'sentence': 'most wondrously gifted artists ', 'label': 1}, {'idx': 55051, 'sentence': 'the one not-so-small problem with expecting is that the entire exercise has no real point . ', 'label': 0}, {'idx': 20225, 'sentence': 'only is entry number twenty the worst of the brosnan bunch ', 'label': 0}]\n"
     ]
    }
   ],
   "source": [
    "# Filter positive and negative examples\n",
    "positive_examples = [example for example in train_set if example[\"label\"] == 1]\n",
    "negative_examples = [example for example in train_set if example[\"label\"] == 0]\n",
    "\n",
    "# Randomly select 2 examples from each\n",
    "random.seed(42)\n",
    "selected_positive = random.sample(positive_examples, 2)\n",
    "selected_negative = random.sample(negative_examples, 2)\n",
    "\n",
    "# Combine selected examples\n",
    "few_shot_examples = selected_positive + selected_negative\n",
    "\n",
    "print(few_shot_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55e43088-e6d8-44e1-b87a-3fd1f016fd9b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: at every opportunity to do something clever \n",
      "Sentiment: Positive\n",
      "Sentence: most wondrously gifted artists \n",
      "Sentiment: Positive\n",
      "Sentence: the one not-so-small problem with expecting is that the entire exercise has no real point . \n",
      "Sentiment: Negative\n",
      "Sentence: only is entry number twenty the worst of the brosnan bunch \n",
      "Sentiment: Negative\n",
      "Sentence: at every opportunity to do something clever \n",
      "Reasoning: This sentence has positive language and expresses satisfaction or praise.\n",
      "Sentiment: Positive\n",
      "Sentence: most wondrously gifted artists \n",
      "Reasoning: This sentence has positive language and expresses satisfaction or praise.\n",
      "Sentiment: Positive\n",
      "Sentence: the one not-so-small problem with expecting is that the entire exercise has no real point . \n",
      "Reasoning: This sentence contains negative language or expresses dissatisfaction.\n",
      "Sentiment: Negative\n",
      "Sentence: only is entry number twenty the worst of the brosnan bunch \n",
      "Reasoning: This sentence contains negative language or expresses dissatisfaction.\n",
      "Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "examples_text = \"\\n\".join(\n",
    "    f\"Sentence: {example['sentence']}\\n\"\n",
    "    f\"Sentiment: {'Positive' if example['label'] == 1 else 'Negative'}\"\n",
    "    for example in few_shot_examples\n",
    ")\n",
    "\n",
    "examples_text_cot = \"\\n\".join(\n",
    "    f\"Sentence: {example['sentence']}\\n\"\n",
    "    f\"Reasoning: {'This sentence has positive language and expresses satisfaction or praise.' if example['label'] == 1 else 'This sentence contains negative language or expresses dissatisfaction.'}\\n\"\n",
    "    f\"Sentiment: {'Positive' if example['label'] == 1 else 'Negative'}\"\n",
    "    for example in few_shot_examples\n",
    ")\n",
    "\n",
    "print(examples_text)\n",
    "print(examples_text_cot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c4bb31-611c-4615-92af-632cb80bef89",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bbe15de-e5e2-4099-942a-c81cbdf3c61c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "def zero_shot(content: str, examples = None):\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=f\"Your goal is to read a sentence and classify its emotion into one of the following categories: {', '.join(label_map.values())}.\\n\\n\"\n",
    "                    f\"Now classify the following sentence. The output MUST follow this format:\\n\"\n",
    "                    f\"Sentiment: [Classification]\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=content\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    response = chat_model.invoke(messages)\n",
    "    return response.content\n",
    "\n",
    "def few_shot(content: str, examples: str):\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=f\"Your goal is to read a sentence and classify its emotion into one of the following categories: {', '.join(label_map.values())}.\\n\\n\"\n",
    "                    f\"Here are some examples:\\n{examples}\\n\\n\"\n",
    "                    f\"Now classify the following sentence. The output MUST follow this format:\\n\"\n",
    "                    f\"Sentiment: [Classification]\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=content\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    response = chat_model.invoke(messages)\n",
    "    return response.content\n",
    "\n",
    "def parse_sentiment(response):\n",
    "    sentiment_pattern = r\"Sentiment:\\s*(.*?)$\"\n",
    "    sentiment_match = re.search(sentiment_pattern, response)\n",
    "\n",
    "    sentiment = sentiment_match.group(1).strip().lower() if sentiment_match else \"invalid\"\n",
    "\n",
    "    if sentiment not in [label for label in label_map.values()]:\n",
    "        sentiment = \"invalid\"\n",
    "\n",
    "    return sentiment\n",
    "\n",
    "def evaluate_model(dataset, fn, examples):\n",
    "    t0 = time()\n",
    "    predictions = []\n",
    "\n",
    "    for idx, (sentence, true_label) in enumerate(zip(dataset[\"sentence\"], dataset[\"label\"]), 1):\n",
    "        prediction = fn(sentence, examples)\n",
    "        sentiment = parse_sentiment(prediction)\n",
    "\n",
    "        predictions.append(sentiment)\n",
    "\n",
    "        if idx % 100 == 0:\n",
    "            print(f\"---\\nSentence: {sentence}\\nTrue: {true_label}\\nPrediction: {sentiment}\")\n",
    "            print(f\"Processed {idx}/{len(dataset)} examples, Time: {time()-t0:.3f}\\n---\\n\")\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def create_reports(dataset, predictions):\n",
    "    calc_accuracy(dataset, predictions)\n",
    "    class_report(dataset, predictions)\n",
    "    conf_matrix(dataset, predictions)\n",
    "    acc_graph(dataset, predictions)\n",
    "\n",
    "def calc_accuracy(dataset, predictions):\n",
    "    true_labels = dataset[\"label\"]\n",
    "    accuracy = sum([1 if p == t else 0 for p, t in zip(predictions, true_labels)]) / len(true_labels) * 100\n",
    "    print(f\"accuracy: {accuracy:.4f}\")\n",
    "\n",
    "def class_report(dataset, predictions):\n",
    "    true_labels = dataset[\"label\"]\n",
    "    print(classification_report(\n",
    "            true_labels, \n",
    "            predictions, \n",
    "            target_names=list(label_map.values()) + [\"invalid\"],\n",
    "            zero_division=0))\n",
    "\n",
    "def conf_matrix(dataset, predictions):\n",
    "    true_labels = dataset[\"label\"]\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(label_map.values()) + [\"invalid\"])\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "\n",
    "def acc_graph(dataset, predictions):\n",
    "    true_labels = dataset[\"label\"]\n",
    "    accuracies = np.cumsum(np.array(true_labels) == np.array(predictions)) / np.arange(1, len(true_labels) + 1)\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(accuracies * 100)\n",
    "    plt.title(\"Accuracy Over Samples\")\n",
    "    plt.xlabel(\"Number of Samples\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de59b5e6-acef-4317-a1de-c2f192fb1a66",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "# Zero-Shot Prompting Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8054a1ec-3a11-4831-9ef7-aed74c3e712f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "Your goal is to read a sentence and determine whether the sentiment is 'Positive' or 'Negative'. You will only respond with 'Positive' or 'Negative'.\n",
      "\n",
      "Now classify the following sentence:<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "The food was absolutely amazing and delightful!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Positive\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "Your goal is to read a sentence and determine whether the sentiment is 'Positive' or 'Negative'. You will only respond with 'Positive' or 'Negative'.\n",
      "\n",
      "Now classify the following sentence:<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "The experience was the worst I've ever had.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "ai_msg = zero_shot(\"The food was absolutely amazing and delightful!\")\n",
    "print(ai_msg)\n",
    "\n",
    "ai_msg = zero_shot(\"The experience was the worst I've ever had.\")\n",
    "print(ai_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240d8d8e-414d-448d-a7ac-633776193cba",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "# Few-Shot Prompting Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96065d23-248e-4877-801e-fbc070e9f3f6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "Your goal is to read a sentence and determine whether the sentiment is 'Positive' or 'Negative'. You will only respond with 'Positive' or 'Negative'. Here are some examples:\n",
      "\n",
      "Sentence: at every opportunity to do something clever \n",
      "Sentiment: Positive\n",
      "Sentence: most wondrously gifted artists \n",
      "Sentiment: Positive\n",
      "Sentence: the one not-so-small problem with expecting is that the entire exercise has no real point . \n",
      "Sentiment: Negative\n",
      "Sentence: only is entry number twenty the worst of the brosnan bunch \n",
      "Sentiment: Negative\n",
      "\n",
      "Now classify the following sentence:<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "The food was absolutely amazing and delightful!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Positive\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "Your goal is to read a sentence and determine whether the sentiment is 'Positive' or 'Negative'. You will only respond with 'Positive' or 'Negative'. Here are some examples:\n",
      "\n",
      "Sentence: at every opportunity to do something clever \n",
      "Sentiment: Positive\n",
      "Sentence: most wondrously gifted artists \n",
      "Sentiment: Positive\n",
      "Sentence: the one not-so-small problem with expecting is that the entire exercise has no real point . \n",
      "Sentiment: Negative\n",
      "Sentence: only is entry number twenty the worst of the brosnan bunch \n",
      "Sentiment: Negative\n",
      "\n",
      "Now classify the following sentence:<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "The experience was the worst I've ever had.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "ai_msg = few_shot(\"The food was absolutely amazing and delightful!\", examples_text)\n",
    "print(ai_msg)\n",
    "\n",
    "ai_msg = few_shot(\"The experience was the worst I've ever had.\", examples_text)\n",
    "print(ai_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f38e63e-0144-4136-ac43-77e210302d49",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "# Few-Shot with Chain-of-Thought Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c1e6e59-1d5f-463e-99b8-14cd2065d0d3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "Your goal is to read a sentence and determine whether the sentiment is 'Positive' or 'Negative'. You will only respond with 'Positive' or 'Negative'. Here are some examples:\n",
      "\n",
      "Sentence: at every opportunity to do something clever \n",
      "Reasoning: This sentence has positive language and expresses satisfaction or praise.\n",
      "Sentiment: Positive\n",
      "Sentence: most wondrously gifted artists \n",
      "Reasoning: This sentence has positive language and expresses satisfaction or praise.\n",
      "Sentiment: Positive\n",
      "Sentence: the one not-so-small problem with expecting is that the entire exercise has no real point . \n",
      "Reasoning: This sentence contains negative language or expresses dissatisfaction.\n",
      "Sentiment: Negative\n",
      "Sentence: only is entry number twenty the worst of the brosnan bunch \n",
      "Reasoning: This sentence contains negative language or expresses dissatisfaction.\n",
      "Sentiment: Negative\n",
      "\n",
      "Now classify the following sentence:<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "The food was absolutely amazing and delightful!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Positive\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "Your goal is to read a sentence and determine whether the sentiment is 'Positive' or 'Negative'. You will only respond with 'Positive' or 'Negative'. Here are some examples:\n",
      "\n",
      "Sentence: at every opportunity to do something clever \n",
      "Reasoning: This sentence has positive language and expresses satisfaction or praise.\n",
      "Sentiment: Positive\n",
      "Sentence: most wondrously gifted artists \n",
      "Reasoning: This sentence has positive language and expresses satisfaction or praise.\n",
      "Sentiment: Positive\n",
      "Sentence: the one not-so-small problem with expecting is that the entire exercise has no real point . \n",
      "Reasoning: This sentence contains negative language or expresses dissatisfaction.\n",
      "Sentiment: Negative\n",
      "Sentence: only is entry number twenty the worst of the brosnan bunch \n",
      "Reasoning: This sentence contains negative language or expresses dissatisfaction.\n",
      "Sentiment: Negative\n",
      "\n",
      "Now classify the following sentence:<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "The experience was the worst I've ever had.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "ai_msg = few_shot_cot(\"The food was absolutely amazing and delightful!\", examples_text_cot)\n",
    "print(ai_msg)\n",
    "\n",
    "ai_msg = few_shot_cot(\"The experience was the worst I've ever had.\", examples_text_cot)\n",
    "print(ai_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058452ce-66c1-4f71-b636-04af15c2d4eb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "# Zero-Shot Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "653ad7ad-6fa1-4d7b-9981-5baee39b7f49",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50/872 examples: Correct=41, Incorrect=9\n",
      "Processed 100/872 examples: Correct=81, Incorrect=19\n",
      "Processed 150/872 examples: Correct=123, Incorrect=27\n",
      "Processed 200/872 examples: Correct=165, Incorrect=35\n",
      "Processed 250/872 examples: Correct=201, Incorrect=49\n",
      "Processed 300/872 examples: Correct=239, Incorrect=61\n",
      "Processed 350/872 examples: Correct=279, Incorrect=71\n",
      "Processed 400/872 examples: Correct=327, Incorrect=73\n",
      "Processed 450/872 examples: Correct=368, Incorrect=82\n",
      "Processed 500/872 examples: Correct=407, Incorrect=93\n",
      "Processed 550/872 examples: Correct=446, Incorrect=104\n",
      "Processed 600/872 examples: Correct=493, Incorrect=107\n",
      "Processed 650/872 examples: Correct=537, Incorrect=113\n",
      "Processed 700/872 examples: Correct=575, Incorrect=125\n",
      "Processed 750/872 examples: Correct=620, Incorrect=130\n",
      "Processed 800/872 examples: Correct=656, Incorrect=144\n",
      "Processed 850/872 examples: Correct=700, Incorrect=150\n",
      "Final Results: Correct=717, Incorrect=155, Accuracy=0.82225\n"
     ]
    }
   ],
   "source": [
    "zero_shot_results = evaluate_model(validation_set, zero_shot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097984a5-d234-4c1e-a50a-a3b37db36183",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "# Few-Shot Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e3b38e3-4ff4-4d9e-846f-582e20e601ae",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50/872 examples: Correct=48, Incorrect=2\n",
      "Processed 100/872 examples: Correct=94, Incorrect=6\n",
      "Processed 150/872 examples: Correct=139, Incorrect=11\n",
      "Processed 200/872 examples: Correct=186, Incorrect=14\n",
      "Processed 250/872 examples: Correct=231, Incorrect=19\n",
      "Processed 300/872 examples: Correct=277, Incorrect=23\n",
      "Processed 350/872 examples: Correct=323, Incorrect=27\n",
      "Processed 400/872 examples: Correct=372, Incorrect=28\n",
      "Processed 450/872 examples: Correct=419, Incorrect=31\n",
      "Processed 500/872 examples: Correct=465, Incorrect=35\n",
      "Processed 550/872 examples: Correct=508, Incorrect=42\n",
      "Processed 600/872 examples: Correct=557, Incorrect=43\n",
      "Processed 650/872 examples: Correct=605, Incorrect=45\n",
      "Processed 700/872 examples: Correct=648, Incorrect=52\n",
      "Processed 750/872 examples: Correct=696, Incorrect=54\n",
      "Processed 800/872 examples: Correct=741, Incorrect=59\n",
      "Processed 850/872 examples: Correct=790, Incorrect=60\n",
      "Final Results: Correct=809, Incorrect=63, Accuracy=0.92775\n"
     ]
    }
   ],
   "source": [
    "few_shot_results = evaluate_model(validation_set, few_shot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68de871-ff3d-4119-bfa1-e33c6a7a790b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "# Few-Shot Chain-of-Thought Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9505b4c-0318-48c5-9376-506797974d6f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50/872 examples: Correct=48, Incorrect=2\n",
      "Processed 100/872 examples: Correct=93, Incorrect=7\n",
      "Processed 150/872 examples: Correct=138, Incorrect=12\n",
      "Processed 200/872 examples: Correct=184, Incorrect=16\n",
      "Processed 250/872 examples: Correct=227, Incorrect=23\n",
      "Processed 300/872 examples: Correct=270, Incorrect=30\n",
      "Processed 350/872 examples: Correct=316, Incorrect=34\n",
      "Processed 400/872 examples: Correct=364, Incorrect=36\n",
      "Processed 450/872 examples: Correct=409, Incorrect=41\n",
      "Processed 500/872 examples: Correct=453, Incorrect=47\n",
      "Processed 550/872 examples: Correct=495, Incorrect=55\n",
      "Processed 600/872 examples: Correct=544, Incorrect=56\n",
      "Processed 650/872 examples: Correct=592, Incorrect=58\n",
      "Processed 700/872 examples: Correct=634, Incorrect=66\n",
      "Processed 750/872 examples: Correct=682, Incorrect=68\n",
      "Processed 800/872 examples: Correct=724, Incorrect=76\n",
      "Processed 850/872 examples: Correct=773, Incorrect=77\n",
      "Final Results: Correct=792, Incorrect=80, Accuracy=0.90826\n"
     ]
    }
   ],
   "source": [
    "few_shot_cot_results = evaluate_model(validation_set, few_shot_cot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
